{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b0a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0630cc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_characters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mall_characters\u001b[49m[\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_characters' is not defined"
     ]
    }
   ],
   "source": [
    "all_characters[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068238a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and un-unicode-encoding data\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "# This function reads the shakespear.txt file into jupyter, it also places \\n where theres a newline and so on.\n",
    "def read_file(filename):\n",
    "    file = unidecode.unidecode(open(filename).read())\n",
    "    return file, len(file)\n",
    "\n",
    "# Turning a string into a tensor\n",
    "# Turns every character into a tensor number corresponding to its position in the embedding.\n",
    "def char_tensor(string):\n",
    "    tensor = np.zeros(len(string))\n",
    "    for c in range(len(string)):\n",
    "        try:\n",
    "            tensor[c] = all_characters.index(string[c])\n",
    "        except:\n",
    "            continue\n",
    "    return tensor\n",
    "\n",
    "def int_to_char(tensor):\n",
    "    #string = np.zeros(len(tensor))\n",
    "    #for i in range(len(tensor)):\n",
    "    string = all_characters[tensor]\n",
    "    return string\n",
    "    \n",
    "    \n",
    "\n",
    "def random_training_set(chunk_len, batch_size):\n",
    "    inp = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    for bi in range(batch_size):\n",
    "        start_index = random.randint(0, file_len - chunk_len)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = file[start_index:end_index]\n",
    "        inp[bi] = char_tensor(chunk[:-1])\n",
    "        target[bi] = char_tensor(chunk[1:])\n",
    "    inp = Variable(inp)\n",
    "    target = Variable(target)\n",
    "#     if args.cuda:\n",
    "#         inp = inp.cuda()\n",
    "#         target = target.cuda()\n",
    "    return inp, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea84efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all data to numbers.\n",
    "file, file_len = read_file('shakespear.txt')\n",
    "data_id = char_tensor(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e941cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the labels, which is the text but embedded and shifted one.\n",
    "# The character after the input is the label.\n",
    "to_onehot = nn.Embedding(1, n_characters) \n",
    "to_onehot.weight.data = torch.eye(n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b05f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM1(\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (lstm): LSTM(1, 256, batch_first=True)\n",
       "  (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc): Linear(in_features=256, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable \n",
    "\n",
    "\n",
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes #nr of classes\n",
    "        self.num_layers = num_layers #nr of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first=True) # LSTM layer\n",
    "        self.fc_1 =  nn.Linear(hidden_size,hidden_size) # First FC layer\n",
    "        self.fc = nn.Linear(hidden_size,num_classes) # Final FC layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers,x.size(0),self.hidden_size, device=x.device)) # hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers,x.size(0),self.hidden_size, device=x.device)) # internal state\n",
    "\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(output)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.fc(self.dropout(out)) #Final Output\n",
    "        return out\n",
    "\n",
    "\n",
    "num_epochs = 30 #2 epochs\n",
    "learning_rate = 0.001 #0.001 lr\n",
    "input_size = 1 #number of features\n",
    "hidden_size = 256 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "num_classes = n_characters\n",
    "device=torch.device('cuda')\n",
    "\n",
    "model = LSTM1(num_classes=num_classes, input_size=input_size, hidden_size=hidden_size, \n",
    "              num_layers=num_layers) #our lstm class\n",
    "model.to(device)\n",
    "# The inputs will be of size: (batch_nr, batch_size, embedding size) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc2e465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  1115294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olle\\AppData\\Local\\Temp\\ipykernel_16500\\3002205204.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  X = torch.tensor(dataX, dtype=torch.float64).reshape(n_patterns, seq_length, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115294, 100, 1]) torch.Size([1115294])\n"
     ]
    }
   ],
   "source": [
    "data_id = char_tensor(file)\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, file_len - seq_length, 1):\n",
    "    seq_in = data_id[i:i + seq_length]\n",
    "    seq_out = data_id[i + seq_length]\n",
    "    dataX.append(seq_in)\n",
    "    dataY.append(seq_out)\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n",
    "X = torch.tensor(dataX, dtype=torch.float64).reshape(n_patterns, seq_length, 1)\n",
    "X = X / float(n_characters)\n",
    "y = torch.tensor(dataY)\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b029e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "BATCH_SIZE = 128\n",
    "loader =  DataLoader(TensorDataset(X, y), shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3af481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loader)\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3b6c3",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6d5cebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch % 100.0 - Loss: 2020729.6110877998Epoch 0: Cross-entropy: 1886346.7019\n",
      "Epoch % 100.0 - Loss: 2005446.4873161316Epoch 1: Cross-entropy: 1865090.4125\n",
      "Epoch % 100.0 - Loss: 2003583.4092292786Epoch 2: Cross-entropy: 1863455.5381\n",
      "Epoch % 100.0 - Loss: 1996046.9385643005Epoch 3: Cross-entropy: 1851456.6763\n",
      "Epoch % 53.98 - Loss: 1071252.1349334717"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(X_batch\u001b[38;5;241m.\u001b[39mfloat()) \n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(prediction,y_batch\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nnlm\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nnlm\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss(reduction=\"sum\") \n",
    "nr_of_batches = len(loader)\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "\n",
    "for epochs in range(num_epochs):\n",
    "    model.train()\n",
    "    loss_epoch = 0\n",
    "    count = 0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device=device)\n",
    "        y_batch = y_batch.to(device=device)\n",
    "        prediction = model(X_batch.float()) \n",
    "        loss = loss_function(prediction,y_batch.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_epoch += torch.Tensor.cpu(loss).detach().numpy()\n",
    "        count+=1\n",
    "        print(\n",
    "        f'\\rEpoch % {round(float(count/nr_of_batches*100),2)} - Loss: {loss_epoch}',end='')\n",
    "    model.eval()    \n",
    "    loss_e = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device=device)\n",
    "            y_batch = y_batch.to(device=device)\n",
    "            y_pred = model(X_batch.float()) \n",
    "            loss_e += torch.Tensor.cpu(loss_function(y_pred, y_batch.long())).detach().numpy()\n",
    "        if loss_e < best_loss:\n",
    "            best_loss = loss_e\n",
    "            best_model = model.state_dict()\n",
    "        print()\n",
    "        print(\"Epoch %d: Validation Loss: %f\" % (epochs, loss_e))\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f526870",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2bb138f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, \"LSTM_shakespear_best.pth\")\n",
    "torch.save(model, \"LSTM_shakespear.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a64a82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her, \n"
     ]
    }
   ],
   "source": [
    "seq_length = 5\n",
    "start = np.random.randint(0, len(file)-seq_length)\n",
    "prompt = file[start:start+seq_length]\n",
    "print(prompt)\n",
    "pattern = char_tensor(prompt)\n",
    "\n",
    "#len(pattern[0])\n",
    "pattern = pattern.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40633c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"her, \"\n",
      "ems wf sh Ah hR Aeom wf hro \n",
      "Throes toomenos YTUOLWER IRUOhetnety te sooeesdRsyoR \n",
      "KLTAIWTEAWI \n",
      "KUIL"
     ]
    }
   ],
   "source": [
    "model_loaded = torch.load(\"LSTM_shakespear.pth\")\n",
    "print('Prompt: \"%s\"' % prompt)\n",
    "with torch.no_grad():\n",
    "    for i in range(100):\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1)) / float(n_characters)\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "        prediction = model_loaded(x)\n",
    "        index = int(prediction.argmax())\n",
    "        result = int_to_char(index)\n",
    "        print(result, end=\"\")\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c0f99",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2d31146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts: ['The ', 'What is ', 'Shall I give ', 'X087hNYB BHN BYFVuhsdbs ']\n",
      "\n",
      "Prompt: The \n",
      "sf hI MTheehsws AR ArYaRdhsow WRIhrehy\n",
      "Aldey Eh hI MNILUUUARAAA \n",
      "GLLhe sh th :ARAeT \n",
      "TRAeres Eh aRdt\n",
      "\n",
      "Prompt: What is \n",
      "the theeyarc th Aou wios theee, I Ter I Tha the soodr,\n",
      "Aod ta test Ahan thane youe to tear shale,\n",
      "Ie\n",
      "\n",
      "Prompt: Shall I give \n",
      "the shall then that the sea the shall the sears,\n",
      "The was the throe the heart To heart that these\n",
      "the\n",
      "\n",
      "Prompt: X087hNYB BHN BYFVuhsdbs \n",
      "thot The sasett that the sher I then the hooorr of the shale the sears of the seats of the shaln of \n"
     ]
    }
   ],
   "source": [
    "prompt1 = ['The ', 'What is ','Shall I give ','X087hNYB BHN BYFVuhsdbs ']\n",
    "\n",
    "\n",
    "print('Prompts: %s' % prompt1)\n",
    "for g in prompt1:\n",
    "    pattern = char_tensor(g).tolist()\n",
    "    print()\n",
    "    print('Prompt: %s' % g)\n",
    "    with torch.no_grad():\n",
    "        for i in range(100):\n",
    "            x = np.reshape(pattern, (1, len(pattern), 1)) / float(n_characters)\n",
    "            x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "            prediction = model_loaded(x)\n",
    "            index = int(prediction.argmax())\n",
    "            result = int_to_char(index)\n",
    "            print(result, end=\"\")\n",
    "            pattern.append(index)\n",
    "            pattern = pattern[1:]\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f19855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
